1：前提知识要求
2：java基础
3：JUC多线程高并发
4：JVM + GC解析
5：消息中间件MQ
6：NoSql数据库Redis
7：Spring原理
8：Netty + RPC
9：网络通讯与协议
10：数据库
11：SpringBoot + SpringCloud + Dubbo
12：项目


3：JUC多线程高并发
	1：请谈谈你对volatile的理解
		1：volatile是Java虚拟机提供的轻量级的同步机制
			1.1：保证可见性
			1.2：不保证原子性
			1.3：禁止指令重排
				遵循hapens-before 先行发生原则
				
			
		2：JMM你谈谈 - 线程安全获得保证
			1：JMM（JAVA内存模型 JAVA Memory Model ，简称JMM），这玩意本事是一种抽象的概念，并不是真实存在的东西，他描述的是一组规则或规范，通过这组
			规范定义了程序中各个变量（包括实例字段，静态字段和构成数组的对象元素）的访问 方式
			
			2：JMM关于同步的规定：
				1：线程解锁前，必须把共享的变量的值刷新回主内存
				2：线程加锁前，必须读取主内存的最新值到自己的工作内存
				3：加锁解锁是同一把锁
				
			由于JVM运行程序的实体是线程，而每个线程创建时，JVM都会为其创建一个工作内存（有些地方称为栈空间 -- 栈帧的概念），工作内存是每个线程
			的私有数据区域，而JAVA内存模型中规定所有的变量都存储在主内存，主内存是共享内存区域，所有线程都可以访问，但线程对变量
			的操作（读取赋值等）必须在工作内存中进行，首先要将变量从主内存拷贝到自己的工作内存空间，然后对变量进行操作，操作完成
			后再将变量写会主内存，不能直接操作主内存中的变量，各个线程中的工作内存中存储着主内存中的变量副本拷贝，因此不同的线程
			间无法访问对方的工作内存，线程间的通讯（传值）必须通过主内存来完成，其简要访问过程如下：
			
				线程A									线程B
				
				本地内存A(共享变量的副本)				本地内存B(共享变量的副本)
				
							********* JMM控制 *********
				
										主内存
						共享变量	共享变量	共享变量
						
			见图片：volatile可视化图片.png
						
			代码：VolatileDemo01.java
			
			/**
				1：验证volatile的可见性
					1.1：假如 int a = 0 ; a 变量之前根本没有添加volatile关键字修饰，没有可见性
					1.2：添加了 volatile关键字，可以解决可见性问题

				2：验证volatile不保证原子性
					2.1：原子性指的是什么？
						不可分割，完整性。某个线程在做某个具体业务的时候，执行中不可以被打扰或者被分割，需要整体完整
						要么同同时成功，要么同时失败。
					2.2 volatile不保证原子性演示。addPlus()
					
					2.3：为什么不能保证原子性 2.2详解
					
					2.4：如何解决原子性
						1：synchronized
						2：java.util.concurrent.atomic.AtomicInteger
			*/
			
			
			1：通过前面对JMM的介绍，，我们可以知道
				各个线程对主内存中共享变量的操作都是各个线程各自拷贝到自己的工作内存进行操作后再写回到主内存中的。
				
				这就可能存在一个线程 A 修改了共享变量X的值，但还未写会主存时，另外一个线程B 又对主存中同一个共享变量X进行操作，
				但此时A线程工作内存中共享变量x对线程B来说并不可见，这种工作内存与主存同步延迟现象就造成了可见性问题。
		
		2.1：可见性
		2.2：原子性
			a++ 在多线程下是非线程安全的，如何不加synchronized解决？
				见T1.java --- javap -c -v T1.class
				图片：可视化方式看字节码.png
			
			
		2.3：volatile 代码演示可见性+不保证原子性代码。
		2.4：有序性：
			
			计算机在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排，一般分为以下三种：
				
				源代码 -> 编译器优化的重排 -> 指令并行的重排 -> 内存系统的重排 -> 最终执行的指令
			
			单线程环境里面确保程序最终执行结果和代码顺序执行的结果一致
			
			处理器在进行重排序时必须要考虑指令之间的数据依赖性
			
			多线程环境中线程交替执行，由于编译器优化重排的存在，两个线程中使用的变量能否保证一致性是无法确定的，结果无法预测
		
			1：重排1
			
				public void mysort(){
					int x = 11; //1
					int y = 12;	//2
					x = x + 5;	//3
					y = x * x;	//4
				}
				1234
				2134
				1324
				4123 不可以 -> 数据依赖性
			
			2：重排2
				案例 1：
					int a,b,x,y = 0;
					线程1：
						x = a;
						b = 1;
					线程2：
						y = b;
						a = 2;
					x = 0 ; y = 0;
				
				如果编译器对这段程序代码执行重排优化后，可能会出现下列情况
				
					线程1：
						b = 1;
						x = a;
					线程2：
						a = 2;
						y = b;
						
					x = 2 ; y = 1;
					
				案例2：ResortDemo.java
						
			3：禁止指令重排小总结
				
				volatile实现禁止指令重排优化，从而避免多线程环境下程序出现乱序执行的现象。

 

		       	先了解下概念，内存屏障（Memory Barrier）又称内存栅栏，是一个CPU指令，它的作用有两个：

				保证特定操作执行的顺序性；
				保证某些变量的内存可见性（利用该特性实现volatile内存可见性）
				 

				volatile实现禁止指令重排优化底层原理：

					由于编译器和处理器都能执行指令重排优化。如果在指令间插入一条Memory Barrier则会告诉编译器和CPU，
					不管什么指令都不能和这条Memory Barrier指令重排，也就是说通过插入内存屏障，就能禁止在内存屏障前后的指令执行重排优化。
					内存屏障另外一个作用就是强制刷出各种CPU的缓存数据，因此任何CPU上的线程都能读取到这些数据的最新版本。

				左边：写操作场景：先LoadStore指令，后LoadLoad指令。

				右边：读操作场景：先LoadLoad指令，后LoadStore指令。

				见：volatile小总结.png
				
				
				线程安全获得保证：
					工作内存与主存同步延迟现象导致的可见性问题
					可以使用synchronized或volatile关键字解决，他们都可以使一个线程修改后的变量立即对其他线程可见。
					
					对于指令重排导致的可见性问题和有序性问题：
					可以利用volatile关键字解决，因为volatile的另外一个作用就是禁止重排序优化。
				
		
		3：你在哪些地方用过volatile
		
			1：单例模式 DCL 代码
			
				详见：SingletonDemo.java
				
				DCL（双端检查锁）机制不一定线程安全，原因是有指令重排序的存在，加入volatile可以禁止指令重排。
				
				原因在于某一个线程执行到第一次检索，读取到instance不为null时，instance的引用对象可能没有完成初始化。
				
				instance = new SingletoneDemo();可以分一下三步完成（伪代码）
				
				memory = allocate(); //1：分配对象内存空间
				instance(memory) //2：初始化对象
				instance = memory //3：设置instance指向刚分配的内存地址，此时instance != null;
				
				步骤2和步骤3不存在数据依赖关系，而且无论重排前还是重排后程序的执行结果在单线程中没有改变，
				因此这种重排序优化是允许的
				
				memory = allocate(); //1：分配对象内存空间
				instance = memory //3：设置instance指向刚分配的内存地址，此时instance != null;
				instance(memory) //2：初始化对象
				
				但是指令重排序只会保证串行语义的执行的一致性（单线程），但并不关心多线程间的语义一致性。
				所以当一条线成访问 instance 不为空时，由于instance实例未必已初始化完成，也就造成了线程安全问题
					
				读写锁，缓存，CAS
			
			2：单利模式volatile分析
				
				1：代码见 SingletonDemo.java
					
					对比VolatileDemo.java的cas保证addAtomic()原子性
				
				2：单例模式volatile分析
					
					见 3.1
		
		
	2：CAS知道吗？
	
		1：cas是什么？
			
			1：比较并且交换
				
				见代码02_cas -- CASdemo.java   和   AtomicInteger的cas图解.png
				
				
			
			2：cas底层原理？如果知道，谈谈你对Unsafe的理解
			
				自旋锁，rt.jar -> sun.misc.Unsafe
				
				1：Unsafe是CAS的核心类，由于Java方法无法直接访问底层访问底层系统，需要通过本地（native）方法来访问，Unsafe相当于一个后门，基于该
				类可以直接操作特定内存的数据。Unsafe类存在于sun.misc包中，其内部方法操作可以像C的指针一样直接操作内存，因为Java中CAS操作的执行依赖
				于Unsafe类的方法。
				
				注意：Unsafe；类中的所有方法都是native修饰的，也就是说Unsafe类中的方法都直接调用操作系统地城资源执行相应的任务。
				
				2：变量valueOffset，表示该变量值在内存中的偏移地址，因为Unsafe就是根据内存偏移地址获取数据的。
					
					public final int getAndIncrement(){
						return unsafe.heyAndAddInt(this,valueOffet,1);
					}
					
				3：变量value用volatile修饰，保证了多线程之间的内存可见性。
				
			3：cas到底是什么？
				
				1：CAS的全称是 Compare-And-Swap ，他是一条CPU并发原语。
				他的功能是判断内存某个位置的值是否为预期值，如果是则更改为新的值，这个过程是原子的。
				
				2：CAS并发原语体现在JAVA语言中就是sun.misc.Unsafe类中的各个方法。调用Unsafe类中的CAS方法，JVM会帮我们实现出CAS汇编指令。
				这是一种完全依赖于硬件的功能，通过他实现了原子操作。再次强调，由于CAS是一种系统原语，原语数据操作系统语言范畴，是由若干条
				指令组成的，用于完成某个功能的一个过程，并且原语的执行必须是连续的，在执行过程中不允许被中断，也就是说CAS是一条CPU的原子指令，
				不会造成所谓的的数据不一致问题。
				
					var1 AtomicInteger对象本身。
					var2 该对象值得引用地址
					var3 需要变动的数量
					var5 是用过var1 var2 找出的主内存中真是的值。
					用该对象当前的值与var5比较
					如果相同，更新var5 + var4 并且返回true。
					如果不同，继续取值然后再比较，直到更新完成。
				
					public final int getAndAddInt(Object var1,long var2,long var4){
						int var5;
						do{
							var5 = this.getIntVolatile(var1,var2);
						}while(!this.compareAndSwapInt(var1,var2,var3,var4 + var5));
						return var5;
					}
			
				3：假设线程A和线程B同时执行getAndAddInt操作（分别跑在不同CPU上）
					
					1：AtomicInteger里面的value原始值为3，即主内存中的AtomicInteger的value为3，根据JMM模型，线程A和线程B各自持有一份
					值为3的value的副本分别到各自的工作内存。
					
					2：线程A通过getIntVolatile(var1,var2) 拿到value值 3，这时线程A被挂起。
					
					3：线程B也通过getIntVolatile(var1,var2) 方法获取到value值3，此时刚好线程B没有被挂起并执行compareAndSwapInt方法比较内存值也为3，
					成功修改内存值为4，线程B打完收工。
					
					4：这时候线程A恢复，执行compareAndSwapInt方法比较，发现自己手里的值数字3和主内存的值数字4不一致了，说明该值已经被其他线程抢先一步
					修改过了，那A线程本次修改失败，只能重新读取重新再来一遍。
					
					5：线程A重新获取value值，因为变量value被volatile修饰，所以其他线程对他的修改，线程A总是能够看到，线程A继续执行compareAndSwapInt进行比较替换，直到成功。
					
				4：底层汇编
				
					Unsafe类中的compareAndSwapInt，是一个本地方法，该方法的实现位于unsafe.cpp中
					
					http://hg.openjdk.java.net/jdk8/jdk8/hotspot/file/tip/src/share/vm/prims/unsafe.cpp			1185行 UNSAFE_ENTRY
					
					
					UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapInt(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jint e, jint x))
					  UnsafeWrapper("Unsafe_CompareAndSwapInt");
					  oop p = JNIHandles::resolve(obj);
					  jint* addr = (jint *) index_oop_from_field_offset_long(p, offset);
					  return (jint)(Atomic::cmpxchg(x, addr, e)) == e;
					UNSAFE_END
					
					先想办法拿到变量value在内存中的地址
					通过Atomic::cmpxchg实现比较替换，其中参数x是即将更新的值，参数e是原内存的值。
				
				5：总结：
					
					1：CAS（CompareAndSwap）
					比较当前工作内存中的值和主内存中的值，如果相同则执行规定操作，否则继续比较直到主内存和工作内存中的值一致为止。
					
					2：CAS应用
					CAS有3个操作数，内存值V，旧的预期值A，要修改的更新值B。
					当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做，再去旋转比较，直到相同为止。
				
		3：cas缺点
		
			1：循环时间长，开销大。
				
				如果CAS失败，会一直尝试。如果CAS长时间一直不成功，可能会给CPU带来很大的运算开销。高并发下面，一万个线程，CPU的利用率攀升。
				虽然并发和一致性保证了，比synchronized轻量了，但是不如synchronized节约CUP开销。但是synchronized同一时间只允许一个线程访问，
				是串行的模式，不如CAS执行效率高。
			
			2：只能保证一个共享变量的原子操作。
			
				当对一个共享变量操作时，我们可以使用循环CAS的方式来保证原子操作。
				但是！！！￥%……&
				对多个共享变量操作的时候，循环CAS就无法保证操作的原子性，这个时候就可以用锁来保证原子性了。因为加锁是保证一段代码原子，CAS只保证一个。
			
			3：引出来ABA的问题 ？？ - 重点，前提是前面的会了。
			
				
	3：原子类AtomicInteger的ABA问题谈谈？原子更新引用知道吗？
	
		1：CAS --> Unsafe --> CAS底层思想 ---> 缺点（ABA问题） ---> 原子引用更新 ---> 如何规避ABA问题？
			
			什么是ABA ？ 狸猫换太子
			
		2：ABA问题如何产生的。
			
			A和 B两个线程，A线程逻辑执行一遍要10秒，B线程执行一遍要1秒，主内存中有一个变量a = 1,A和B线程同时将a读取到各自的栈帧工作内存空间中，
			A开始执行，B开始执行
			线程B 先把a 修改为 2
			此时线程A没执行完毕、
			这时线程B把值改为 3
			依次类推，但是在第9秒的时候把a的值修改回了 1
			这个时候A线程执行完毕，CAS自旋发现值没变，是a = 1，就认为值没有改变，把a = 10赋值给了主内存空间里的a变量。
			看似和谐，其实问题大了去了。
			只顾头和腚。。。
			
		3：	解决ABA问题？？？原子引用。理解原子引用   见 AtomicReferenceDemo.java
		
			原子Integer，原子Boolean。。。类型都可以，但是我想要一个原子User，原子Order怎么办？？
			
				AtomicReference<V>
		
		4：时间戳原子引用 - 怎么解决ABA问题：理解原子引用 + 新增一种机制，修改版本号，类似于时间戳，乐观更新
			
			T1	100	1
			T2	100	1	->	T2	101	2	->	T2	100	3
			
			1：AtomicStampedReference<V> 	见 ABADemo.java
		
			
			
	
	4：我们知道ArrayList是线程不安全的，清编码写一个不安全的案例并给出解决方案。
	
		1:ArrayList线程不安全问题。ContainerNotSateDemo.java
		
		2：故障现象，CME
		
		3：导致原因：
		
			并发争抢修改，导致modelCount和size不一致，触发了ConcurrentModifiyException
		
		4：解决方案：
			
			1:Vector
				1：Vector出现于1.0版本
				2：加锁，大量synchronized修饰，导致其并发量急剧下降
				3：默认初始值大小为10，扩容机制为2倍扩容
			
			2：ArrayList
				1：ArrayList出现于1.2
				2：ArrayList为了杜绝并发量下降的情况，不加锁。
				3：默认初始大小为10，jdk1.5之前 size * 3 / 2 + 1	1.6以后	size + size >> 1
				
			Collection和Collections的区别？
				集合父接口。。。
				集合辅助类。。。
			
			不许用Vector...
			
			Collections.synchronizedList(new ArrayList<>());构建一个线程安全的ArrayList...
			不仅仅synchronizedList。。。还有synchronizedMap,synchronizedSet,synchronizedCollection,synchronizedSortedMap,synchronizedSortedSet.....等等等等。
			
			不许用 Collections的工具
			
			java.util.concurrent.CopyOnWriteArrayList<E>..写时复制
			
			写入时，copy一份原来的List，扩容（size + 1）,CopyOnWrite大意容器就是在写时复制的容器。AQS独占锁，往一个容器添加元素的时候，不直接往容器Object[]添加，
			而是先将当前容器Object[]进行copy,复制出一个新的容器Object[] newElements，然后往新的Object[] newElements里面添加元素，添加元素成功之后，再将原容器的
			引用指向新的容器 setArray(newElements)。这样做的好处是可以对CopyOnWrite容器进行并发读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器
			也是一种读写分离的思想，读和写不同的容器。
			
			详见 CopyOnWriteArrayList.add(E e) 源码
			
			3：HashSet线程是否安全？？？
				不安全
				如何安全？同上。。。+ CopyOnWriteArraySet<E>
				
				1：面试题：
					
					1：HashSet底层是什么？？hash表。底层就是HashMap，只不过是实现了Collection父接口，来操作Map而已。。。
				
					2：那么我调用HashSet的add方法的时候，.add("a")，但是Map是k,v键值对，但是我只add了v，怎么解释？（兵不厌诈啊）
						在调用HashSet的add方法的时候，HashSet封装的add方法，把传来的值作为Map的key，value用了一个Object名字叫PRESENT的静态常量对象。
						其实HashSet只关心Map的key。
			
		
		5：如何避免？优化建议
		
			ArrayList换成Vector，或者Collections.synchronizedList(List<E> list) , 再或者 CopyOnWriteArrayList
			
			HashSet 换成 juc下的CopyOnWriteSet 或者 Collections.synchronizedSet(Set set);
			
			HashMap 换成 HashTable 或者 juc下的 ConcurrentHashMap 或者 Collections.synchronizedMap(Map map);
		
		6：小练习~
		
			值传递引用传递问题：
				
				TestTransferValue.java
	
	5：公平锁\非公平锁\可重入锁\递归锁\自旋锁\读锁\写锁\分段锁 谈谈你的理解，请手写一个自旋锁
	
		手写自旋锁：Unsafe类 + CAS思想
		
		1：公平锁\非公平锁：
			
			1：是什么：
			
				1：公平锁：
					是指多个线程按照申请锁的顺序来获取锁，类似于排队打饭，先来后到
				
				2：非公平锁：
					是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能申请后的线程比申请前的线程优先获取锁
					在高并发的情况下，有可能会造成优先级翻转或者饥饿现象
			
			2：两者区别：
			
				1：公平锁\非公平锁
					并发包中ReentrantLock的创建可以指定构造方法的boolean类型得到公平锁或非公平锁，默认是非公平锁
					
				2：关于两者的区别：
					
					1：公平锁 ：Threads acquire a fair lock in the order in which they requested it
					
						公平锁就是很公平，在并环境中，每个线程在获取锁时会先查看此锁维护的等待队列，如果为空，或者当前线程是等待队列的第一个，就占有锁，否则就会加入到等待队列中，
						以后会按照FIFO的规则从队列中取到自己
					
					2：非公平锁：a nonfair lock permits barging : threads requesting a lock can jump ahead of the queue of waiting thread if the lock happens to be available when it is requested.
					
						非公平锁比较直接，上来就直接尝试占有锁，如果尝试失败，就再采用类似公平锁的那种方式。
			
			3：多说一句：
			
				Java的ReentrantLock 来说，通过无参构造创建的对象是非公平锁，默认boolean fair为false。非公平锁的优点在于吞吐量比公平锁大。
				
				对于synchronized而言，也是一种非公平锁。
			
		2：可重入锁（递归锁）：
		
			1：是什么：
			
				可重入锁（递归锁）指的是同一线程外层方法获得锁之后，内层递归方法仍然能够获取该锁的代码。
				在同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁
				
				线程可以进入任何一个它已经拥有的锁所同步着的代码块。
				（大门上锁 -> 茅房，厨房，卧房随便去。）
				
				public synchronized void get01(){
					get02();
				}
				
				public synchronized void get02(){
					//TODO something
				}
			
			2：ReentrantLock/synchronized 就是一个典型的可重入锁（默认非公平的可重入锁）
				ReentrantLockDemo02.java Phone implements Runnable
				
				11	 invoked get()
				11	 ##############invoked set()
				12	 invoked get()
				12	 ##############invoked set()
				
				假如说Lock lock = new ReentrantLock()
				lock.lock()
				lock.lock()
				
				lock.unlock()
				lock.unlock()
				会出现什么现象？？？
				编译不报错，运行不出错，和一个lock、unlock的效果一样，就是说lock unlock必须是成对出现的
				
				假如 lock.lock()少一个会导致程序卡死，产生死锁
				假如 lock.unlock()少一个，会报错 java.lang.IllegalMonitorStateException
				
				切记两两配对。
				
			
			3：可重入锁最大的作用是避免死锁
			
				get01() 进入方法获得到一把锁，get02()也有一把锁，即同步方法访问同步方法（同一线程外层方法获得锁之后，内层递归方法仍然能够获取该锁的代码），能够互通
			
			4：ReentrantLockDemo.java
		
		3：独占锁\共享锁
		
			1：理论：
				独占锁：指该锁一次只能被一个线程所持有。对ReentrantLock和Synchronized而言都是独占锁
				
				共享锁：指该锁可被多个线程所持有
				
				对ReentrantReadWriteLock来说，其读锁是共享锁，其写锁是独占锁。
				读锁的共享可保证并发读是非常高效的，读写，写读，写写的过程是互斥的。
			
			2：为什么会出现ReentrantReadWriteLock?
				
				1：保证数据一致性
				2：保证并发性
			
				之前加锁，有且仅有一个人可以操作。读写锁，一边读，一边写互不影响。
				
			3：读写锁怎么写？
			
				小提示：
					多个线程同时读一个资源类没有任何问题，所以为了满足并发量，读取共享资源应该可以同时进行。
					但是如果一个线程想去写共享资源来，就不能且不应该再有其他线程对该资源进行读或者写
				总结：
					读-读可以共存
					读-写不可共存
					写-写不可共存
					
					写操作：原子+独占，整个过程必须是一个完整的统一体，中间不允许被分割，被打断
					写操作独占，不可中断
					
				ReadWriteLockDemo.java
				
				ReadWriteLockDemo.png
			
			
		
		4：自旋锁：（Unsafe类 + CAS自旋思想）
		
			是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式尝试获取锁，这样的好处是减少线程上线文的切换和消耗，缺点是循环会消耗CPU。
			
			public final int getAndAddInt(Object var1, long var2, int var4) {
				int var5;
				do {
					var5 = this.getIntVolatile(var1, var2);
				} while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));

				return var5;
			}
		
			1：请手写一个自旋锁：
				
				自旋锁的优点，循环比较获取直到成功为止，没有类似wait的阻塞
				通过CAS操作完成自旋锁，A线程先进来调用myLock方法让自己持有锁5秒钟，B随后进来发现当前有线程持有锁，不是null，所以只能通过自旋等待，
				直到A释放锁后B随后抢到。
				
				SpinLockDemo.java
	
		
	
	6：CountDownLatch\CyclicBarrier\Semaphore使用过吗？
	
		1：java.util.concurrent.CountDownLatch，API里面大概的意思就是说给定一个初始值，await()将会一直阻塞，每次调用countDown() -1 ，一直减到0为止。
		
			秦国一统天下。
		
			示例：CountDownLatchDemo.java
	
			小总结：
				1：CountDownLatch让一些线程阻塞直到另一些线程完成一系列操作后才被唤醒
				2：CountDownLatch主要有俩方法，当一个或者多个线程调用await()方法时，调用线程会被阻塞。
				其他线程调用countDown()方法会将计数器-1（调用countDown()方法的线程不会被阻塞），当计数器
				的值变成0的时候，因调用await()方法被阻塞的线程会被唤醒，继续执行。
				
		2：CyclicBarrier
		
			1：CyclicBarrier是什么意思？
				和CountDownLatch做减法的方式完全相反，这个是做加法，七颗龙珠召唤神龙。
				CyclicBarrier的字面意思是可循环（Cyclic）使用的屏障（Barrier）。他要做的事情是，
				让一组线程到达一个屏障（也可以叫做同步点）时被阻塞，直到最后一个线程到达屏障时，
				屏障才会开门，所有被屏障拦截的线程才会继续干活，线程进入屏障通过CyclicBarrier的await()方法。
				
			2：CyclicBarrierDemo.java
			
		3：Semaphore 信号灯，信号量（抢车位。。） 和 google的 RateLimiter很相似，只不过Semaphore底层基于了AQS，RateLimiter基于漏桶算法
			
			1：是什么？
				
				信号量主要用于两个目的，一个是用于多个共享资源的互斥使用，另一个用于并发线程数的控制。
				
				可伸缩，可变化，限流（小米在用）
				
			2：代码：
				
				SemaphoreDemo.java
			
		
	
	7：阻塞队列知道吗？
	
		1：队列，FIFO 与之相对的 栈Stack FILO
		
		2：阻塞队列
		
			1：思考
			
				1：Block + Queue 有没有好的一面？
				
				2：阻塞不阻塞，如何管理？（回想一下线程的生产消费问题。）
			
			2：阻塞队列是什么？
			
				1：满了就不放了，没了就不取了。
				
					见图片：什么是阻塞队列.png
					
			3：为什么用？有什么好处？
			
				在多线程领域：所谓的阻塞，在某些情况下会挂起线程（即阻塞），一旦满足条件，被挂起的线程会被唤醒。（自动、手动）
				
				那么为什么需要BlockingQueue呢？这得从BlockingQueue的好处开始说起，好处是我们不需要去关心什么时候需要阻塞线程，
				也不用关心什么时候去唤醒线程，这一切的一切都被BlockingQueue给承包了。
				
				在concurrent包发布之前，在多线程环境下，我们每个程序员都必须去自己控制这些细节，最简单的例子就是多线程的生产者消费，synchronized + wait() + notify()/notifyAll()...
				这一系列的操作确实666，但是控制不好的话。。666..主要的难点还是在于死锁之类的问题，BlockingQueue的出现，解放了我们，使我们不用去控制这些细节，还能兼顾效率和线程的安全。
				给我们的程序带降低了不小的复杂程度。
				
			4：BlockingQueue的核心方法
			
				见图片：BlockingQueue的核心方法.png
			
				BlockingQueueDemo.java
			
			5：架构梳理+种类分析
			
				1：见图片：常用的BlockingQueue.png 七个。。
				
				2：种类分析：
				
					1：ArrayBlockingQueue：由数组结构组成的有界阻塞队列
					2：LinkedBlockingQueue：由链表结构组成的有界（但是大小默认为 Integer.MAX_VALUE）的阻塞队列 2147483647。。会OMM
					3：PriorityBlockingQueue：支持优先级排序的误解阻塞队列
					4：DelayQueue：使用优先级队列实现的延迟无界队列
					5：SynchronousQueue：不存储元素的阻塞队列，也叫单个元素队列
						1：理论：
						
							SynchronousQueue没有容量
							与其他的BlockingQueue不同，SynchronousQueue是一个不存储元素的BlocingQueue
							每一个put操作必须要等待一个take操作，否则不能继续添加元素，反之亦然。
						
						2：
					6：LinkedTransferQueue：由链表结构组成的无界队列
					7：LinkedBlockingDeque：由链表结构组成的双向阻塞队列
					
				3：重点：（线程池的底层就这三个。）
					1：ArrayBlockingQueue
					2：LinkedBlockingQueue
					3：SynchronousQueue
					
				4：LinkedBlockingDeque Deque双端队列。
			

			6：用在哪？
				
					
	
	8：线程池用过吗？ThreadPoolExecutor谈谈你的理解
	9：线程池用过吗？生产商你如何设置合理参数的？
	10：死锁编码及定位分析
	11：Java里面锁请谈谈你的理解，能说多少说多少

4：JVM + GC解析
	1：JVM垃圾回收的时候如何确定垃圾？
	2：你说你做过JVM调优和参数配置，请问你如何查看JVM系统默认值？
	3：你平时工作用过的JVM常用基本配置参数有哪些？
	4：请谈谈你对OOM的认识
		1：java.lang.StackOverflowError
		2：java.lang.OutOfMemoryError	java heap space
		3：java.lang.OutOfMemoryError	GC overhead limit exceeded
		4：java.lang.OutOfMemoryError	Direct buffer memory
		5：java.lang.OutOfMemoryError	Metaspace
		6：java.lang.OutOfMemoryError	unable to create new native thread
		7：java.lang.OutOfMemoryError	Requested array size exceeds VM limit
		
	5：GC回收算法和垃圾收集器的关系？另外，串行收集\并行收集\并发收集\STW是什么？
	6：怎么查看服务器默认的垃圾收集器？默认的垃圾收集器是什么？生产上你是如何配置垃圾收集器的？谈谈你的理解。
	7：G1垃圾收集器
	8：强引用、软引用、弱引用、虚引用分别是什么？
	9：生产环境服务器变慢，诊断思路和性能评估谈谈？
	10：假如生产环境出现CPU占用过高，请谈谈你的分析思路和定位。
	11：对于JDK自带的JVM监控和性能分析工具用过哪些？一般你是怎么用的？
		性能监控工具
			1：jps
			2：jinfo
			3：jmap
			4：jstat
			5：jstack
			
	12：JVM的字节码指令接触过么？


5：消息中间件MQ
	1：消息队列的主要作用是什么？
	2：你项目好好的情况下，为什么要引入消息队列？引入的理由是什么？
	3：项目里你们是怎么用消息队列的？
	4：在你的项目中是如何保证消息队列高可用的？
	5：kafka、activeMQ、RabbitMq、RocketMq都有什么区别？
	6：MQ在高并发情况下，假设队列满了如何防止消息丢失？
	7：消费者消费消息，如何保证MQ幂等性？
	8：谈谈你对私信队列的理解？
	9：如果百万级别的消息积压了，你们如何处理？
	10：你们为什么不用其他的MQ，最终选择了RocketMq？


6：NoSql数据库Redis
	1：在你的项目中，那些数据是数据库和Redis缓存双写一份的？如何保证双写一致性？
	2：系统上线，Redis缓存系统是如何部署的？
	3：系统上线，Redis缓存给了多大的总内存？命中率多高？抗住了多少QPS？数据流回源会有多少QPS？
	4：热Key大Value问题，某个key出现了热点缓存，导致缓存集群中某个机器负载过高，如何发现并解决？
	5：超大Value打满网卡的问题如何规避这样的问题？
	6：你过往的工作经历中，是否出现了缓存集群事故？说说细节并说说高并发高可用保障的方案
	7：平时如何监控缓存集群的QPS和容量？
	8：缓存集群如何扩容？
	9：说下Redis的集群原理和选举机制？
	10：Key寻址算法都有哪些？
	11：Redis线程模型现场画个图说说？
	12：Redis内存模型现场画个图说说
	13：Redis的底层数据结构了解多少？
	14：Redis的单线程特性有什么优点和缺点？
	15：你们怎么解决缓存击穿的问题？
	
	
